{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "DMBI DesicionTree,Navie Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pinky-Chaudhary/py/blob/master/DMBI_DesicionTree%2CNavie_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFnh-lNKJjuX",
        "outputId": "4994feab-03c5-4f10-ed5a-2a538884aa20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "import pandas as pd\n",
        "from itertools import combinations,permutations,chain\n",
        "import numpy as np\n",
        " \n",
        "class Apriori:\n",
        "    def __init__(self,df,df1,min_sup,min_conf):\n",
        "        self.df = df\n",
        "        self.df1 = df1\n",
        "        self.min_sup = min_sup\n",
        "        self.min_conf = min_conf\n",
        "        self.item_set = df1.columns\n",
        "        \n",
        "    def getRules(self):\n",
        "        rules=[]\n",
        "        for i in range(1,len(self.item_set)+1):\n",
        "            rules.append(list(combinations(self.item_set,i)))  \n",
        "        print(rules)\n",
        "        return rules\n",
        "    \n",
        "    def getFrequentItemSet(self):\n",
        "        fequent_itemset=dict()\n",
        "        rules = self.getRules()\n",
        "        for i in self.item_set:\n",
        "            if self.df1[i].mean() >= self.min_sup:\n",
        "                fequent_itemset[i]=round(self.df1[i].mean(),2)\n",
        "        for rule in rules:\n",
        "            for i in rule:\n",
        "                result = [True for i in range(len(self.item_set)+1)]\n",
        "                for j in range(0,len(i)):\n",
        "                    result = np.logical_and(result,self.df[i[j]])\n",
        "                if result.mean() >=self.min_sup:\n",
        "                    fequent_itemset[i] = round(result.mean(),2)\n",
        "        print(fequent_itemset)\n",
        "        return fequent_itemset         \n",
        "        \n",
        "    def getRulesWithMinConfidence(self):\n",
        "        frequent_itemset = self.getFrequentItemSet()\n",
        "        L = tuple(list(frequent_itemset.keys())[-1])\n",
        "        subset = map(tuple,sorted(chain(*[combinations(L,i+1) for i,a in enumerate(L)])))\n",
        "        Confidence_set =[]\n",
        "        for i in subset:\n",
        "            remain = set(L).difference(set(i))\n",
        "            if(len(remain) > 0):\n",
        "                confidence = round(frequent_itemset[L]/frequent_itemset[i],2)\n",
        "                if confidence >= self.min_conf:\n",
        "                    Confidence_set.append([list(i),list(remain),confidence])\n",
        " \n",
        "        return Confidence_set\n",
        " \n",
        " \n",
        " \n",
        "def main():\n",
        "    print(\"----------------Apriori Algorithm----------------\")\n",
        "    min_sup = float(input(\"Enter Minimum Support: \"))\n",
        "    min_conf = float(input(\"Enter Minimum Confidence: \"))\n",
        "    filepath = input(\"Enter File Path: \")\n",
        "    df = pd.read_csv(filepath)\n",
        "    df1 = df['Transaction'].str.get_dummies(sep=',')\n",
        "    df[df1.columns] = df1\n",
        "    print(df1)\n",
        "    a = Apriori(df,df1,min_sup,min_conf)\n",
        "    Confidence_Set = a.getRulesWithMinConfidence()\n",
        "    print(\"Anticident=>Consequent      Confidence\")\n",
        "    for i,j,conf in Confidence_Set:\n",
        "        \n",
        "        print(i,\"=>\",j,\"       \",conf)\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------Apriori Algorithm----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH9DToAuJjue"
      },
      "source": [
        "# /content/APRIORI1.CSV\n",
        "\"C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\pinky\\\\sem7\\\\DMBI\\\\APRIORI1.CSV\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DdQoJOrRBX_"
      },
      "source": [
        "training_data = [\n",
        "           ['Positive','Low','High','Up'],\n",
        "           ['Negative','High','Low','Down'],\n",
        "           ['Positive','Low','High','Up'],\n",
        "           ['Positive','High','High','Up'],\n",
        "           ['Negative','Low','High','Down'],\n",
        "           ['Positive','Low','Low','Down'],\n",
        "           ['Negative','High','High','Down'],\n",
        "           ['Negative','Low','High','Down'],\n",
        "           ['Positive','Low','Low','Down'],\n",
        "           ['Positive','High','High','Up'],\n",
        "]\n",
        "header = ['PAST_TREND','OPEN_INTREST','TRADING_VALUE','RETURN']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxgVh2WvYJ90"
      },
      "source": [
        "def unique_vals(rows, col):\n",
        "    \"\"\"Find the unique values for a column in a dataset.\"\"\"\n",
        "    return set([row[col] for row in rows])\n",
        "\n",
        "def class_counts(rows):\n",
        "    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
        "    counts = {}  # a dictionary of label -> count.\n",
        "    for row in rows:\n",
        "        # in our dataset format, the label is always the last column\n",
        "        label = row[-1]\n",
        "        if label not in counts:\n",
        "            counts[label] = 0\n",
        "        counts[label] += 1\n",
        "    return counts\n",
        "\n",
        "def is_numeric(value):\n",
        "    \"\"\"Test if a value is numeric.\"\"\"\n",
        "    return isinstance(value, int) or isinstance(value, float)\n",
        "\n",
        "class Question:\n",
        "    \"\"\"A Question is used to partition a dataset.\n",
        "    This class just records a 'column number' and a 'column value'.\n",
        "    \"\"\"\n",
        "    def __init__(self, column, value):\n",
        "        self.column = column\n",
        "        self.value = value\n",
        "    def match(self, example):\n",
        "        # Compare the feature value in an example to the\n",
        "        # feature value in this question.\n",
        "        val = example[self.column]\n",
        "        if is_numeric(val):\n",
        "            return val >= self.value\n",
        "        else:\n",
        "            return val == self.value\n",
        "\n",
        "    def __repr__(self):\n",
        "        # This is just a helper method to print\n",
        "        # the question in a readable format.\n",
        "        condition = \"==\"\n",
        "        if is_numeric(self.value):\n",
        "            condition = \">=\"\n",
        "        return \"Is %s %s %s?\" % (header[self.column], condition, str(self.value))\n",
        "\n",
        "def partition(rows, question):\n",
        "    \"\"\"Partitions a dataset.\n",
        "\n",
        "    For each row in the dataset, check if it matches the question. If\n",
        "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
        "    \"\"\"\n",
        "    true_rows, false_rows = [], []\n",
        "    for row in rows:\n",
        "        if question.match(row):\n",
        "            true_rows.append(row)\n",
        "        else:\n",
        "            false_rows.append(row)\n",
        "    return true_rows, false_rows\n",
        "\n",
        "def gini(rows):\n",
        "    \"\"\"Calculate the Gini Impurity for a list of rows. \"\"\"\n",
        "    counts = class_counts(rows)\n",
        "    impurity = 1\n",
        "    for lbl in counts:\n",
        "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
        "        impurity -= prob_of_lbl**2\n",
        "    return impurity\n",
        "\n",
        "def info_gain(left, right, current_uncertainty):\n",
        "    \"\"\"Information Gain.\n",
        "    The uncertainty of the starting node, minus the weighted impurity of\n",
        "    two child nodes.\n",
        "    \"\"\"\n",
        "    p = float(len(left)) / (len(left) + len(right))\n",
        "    return current_uncertainty - p * gini(left) - (1 - p) * gini(right)\n",
        "\n",
        "def find_best_split(rows):\n",
        "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
        "    and calculating the information gain.\"\"\"\n",
        "    best_gain = 0  # keep track of the best information gain\n",
        "    best_question = None  # keep train of the feature / value that produced it\n",
        "    current_uncertainty = gini(rows)\n",
        "    n_features = len(rows[0]) - 1  # number of columns\n",
        "\n",
        "    for col in range(n_features):  # for each feature\n",
        "\n",
        "        values = set([row[col] for row in rows])  # unique values in the column\n",
        "\n",
        "        for val in values:  # for each value\n",
        "\n",
        "            question = Question(col, val)\n",
        "\n",
        "            # try splitting the dataset\n",
        "            true_rows, false_rows = partition(rows, question)\n",
        "\n",
        "            # Skip this split if it doesn't divide the\n",
        "            # dataset.\n",
        "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
        "                continue\n",
        "\n",
        "            # Calculate the information gain from this split\n",
        "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
        "\n",
        "            # You actually can use '>' instead of '>=' here\n",
        "            # but I wanted the tree to look a certain way for our\n",
        "            # toy dataset.\n",
        "            if gain >= best_gain:\n",
        "                best_gain, best_question = gain, question\n",
        "\n",
        "    return best_gain, best_question\n",
        "\n",
        "class Leaf:\n",
        "    \"\"\"A Leaf node classifies data. \"\"\"\n",
        "\n",
        "    def __init__(self, rows):\n",
        "        self.predictions = class_counts(rows)\n",
        "\n",
        "class Decision_Node:\n",
        "    \"\"\"A Decision Node asks a question.\n",
        "    This holds a reference to the question, and to the two child nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,question,true_branch,false_branch):\n",
        "        self.question = question\n",
        "        self.true_branch = true_branch\n",
        "        self.false_branch = false_branch\n",
        "\n",
        "def build_tree(rows):\n",
        "    \"\"\"Builds the tree.\n",
        "\n",
        "    Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
        "    for the base case (no further information gain). 3) Prepare for\n",
        "    giant stack traces.\n",
        "    \"\"\"\n",
        "\n",
        "    # Try partitioing the dataset on each of the unique attribute,\n",
        "    # calculate the information gain,\n",
        "    # and return the question that produces the highest gain.\n",
        "    gain, question = find_best_split(rows)\n",
        "\n",
        "    # Base case: no further info gain\n",
        "    # Since we can ask no further questions,\n",
        "    # we'll return a leaf.\n",
        "    if gain == 0:\n",
        "        return Leaf(rows)\n",
        "\n",
        "    # If we reach here, we have found a useful feature / value\n",
        "    # to partition on.\n",
        "    true_rows, false_rows = partition(rows, question)\n",
        "\n",
        "    # Recursively build the true branch.\n",
        "    true_branch = build_tree(true_rows)\n",
        "\n",
        "    # Recursively build the false branch.\n",
        "    false_branch = build_tree(false_rows)\n",
        "\n",
        "    # Return a Question node.\n",
        "    # This records the best feature / value to ask at this point,\n",
        "    # as well as the branches to follow\n",
        "    # dependingo on the answer.\n",
        "    return Decision_Node(question, true_branch, false_branch)\n",
        "\n",
        "def print_tree(node, spacing=\"\"):\n",
        "    \"\"\"World's most elegant tree printing function.\"\"\"\n",
        "\n",
        "    # Base case: we've reached a leaf\n",
        "    if isinstance(node, Leaf):\n",
        "        print (spacing + \"Predict\", node.predictions)\n",
        "        return\n",
        "\n",
        "    # Print the question at this node\n",
        "    print (spacing + str(node.question))\n",
        "\n",
        "    # Call this function recursively on the true branch\n",
        "    print (spacing + '--> True:')\n",
        "    print_tree(node.true_branch, spacing + \"  \")\n",
        "\n",
        "    # Call this function recursively on the false branch\n",
        "    print (spacing + '--> False:')\n",
        "    print_tree(node.false_branch, spacing + \"  \")\n",
        "\n",
        "DecisionTree = build_tree(training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK-BB3D8Y1RH"
      },
      "source": [
        "print_tree(DecisionTree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr2SMAiwZF-2"
      },
      "source": [
        "def classify(row, node):\n",
        "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
        "    # Base case: we've reached a leaf\n",
        "    if isinstance(node, Leaf):\n",
        "        return node.predictions\n",
        "    # Decide whether to follow the true-branch or the false-branch.\n",
        "    # Compare the feature / value stored in the node,\n",
        "    # to the example we're considering.\n",
        "    if node.question.match(row):\n",
        "        return classify(row, node.true_branch)\n",
        "    else:\n",
        "        return classify(row, node.false_branch)\n",
        "def print_leaf(counts):\n",
        "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
        "    total = sum(counts.values()) * 1.0\n",
        "    probs = {}\n",
        "    for lbl in counts.keys():\n",
        "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCl4WBLKZ7zu",
        "outputId": "4e27b4f9-fa85-4c5f-a9e3-ff8b3af2c14f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "testing_data = ['Negative','High','High']\n",
        "print_leaf(classify(testing_data, DecisionTree))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Down': '100%'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA_Y-nVjaBsE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHwtH84GaDWk",
        "outputId": "ced7d67c-6f74-4118-8f45-7fc458e8842d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "# Make Predictions with Naive Bayes On The Iris Dataset\n",
        "from csv import reader\n",
        "from math import sqrt\n",
        "from math import exp\n",
        "from math import pi\n",
        "\n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        "\n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        "\n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\t\tprint('[%s] => %d' % (value, i))\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        "\n",
        "# Split the dataset by class values, returns a dictionary\n",
        "def separate_by_class(dataset):\n",
        "\tseparated = dict()\n",
        "\tfor i in range(len(dataset)):\n",
        "\t\tvector = dataset[i]\n",
        "\t\tclass_value = vector[-1]\n",
        "\t\tif (class_value not in separated):\n",
        "\t\t\tseparated[class_value] = list()\n",
        "\t\tseparated[class_value].append(vector)\n",
        "\treturn separated\n",
        "\n",
        "# Calculate the mean of a list of numbers\n",
        "def mean(numbers):\n",
        "\treturn sum(numbers)/float(len(numbers))\n",
        "\n",
        "# Calculate the standard deviation of a list of numbers\n",
        "def stdev(numbers):\n",
        "\tavg = mean(numbers)\n",
        "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
        "\treturn sqrt(variance)\n",
        "\n",
        "# Calculate the mean, stdev and count for each column in a dataset\n",
        "def summarize_dataset(dataset):\n",
        "\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
        "\tdel(summaries[-1])\n",
        "\treturn summaries\n",
        "\n",
        "# Split dataset by class then calculate statistics for each row\n",
        "def summarize_by_class(dataset):\n",
        "\tseparated = separate_by_class(dataset)\n",
        "\tsummaries = dict()\n",
        "\tfor class_value, rows in separated.items():\n",
        "\t\tsummaries[class_value] = summarize_dataset(rows)\n",
        "\treturn summaries\n",
        "\n",
        "# Calculate the Gaussian probability distribution function for x\n",
        "def calculate_probability(x, mean, stdev):\n",
        "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
        "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
        "\n",
        "# Calculate the probabilities of predicting each class for a given row\n",
        "def calculate_class_probabilities(summaries, row):\n",
        "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\n",
        "\tprobabilities = dict()\n",
        "\tfor class_value, class_summaries in summaries.items():\n",
        "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
        "\t\tfor i in range(len(class_summaries)):\n",
        "\t\t\tmean, stdev, _ = class_summaries[i]\n",
        "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
        "\treturn probabilities\n",
        "\n",
        "# Predict the class for a given row\n",
        "def predict(summaries, row):\n",
        "\tprobabilities = calculate_class_probabilities(summaries, row)\n",
        "\tbest_label, best_prob = None, -1\n",
        "\tfor class_value, probability in probabilities.items():\n",
        "\t\tif best_label is None or probability > best_prob:\n",
        "\t\t\tbest_prob = probability\n",
        "\t\t\tbest_label = class_value\n",
        "\treturn best_label\n",
        "\n",
        "# Make a prediction with Naive Bayes on Iris Dataset\n",
        "filename = filenames\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])-1):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# fit model\n",
        "model = summarize_by_class(dataset)\n",
        "# define a new record\n",
        "row = [5.7,2.9,4.2,1.3]\n",
        "# predict the label\n",
        "label = predict(model, row)\n",
        "print('Data=%s, Predicted: %s' % (row, label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-77d38e4281d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# Make a prediction with Naive Bayes on Iris Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mstr_column_to_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-77d38e4281d1>\u001b[0m in \u001b[0;36mload_csv\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mcsv_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHNp1exmnlPJ"
      },
      "source": [
        "filenames= 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDvaQw9Zpf0i"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "training_data =[\n",
        "                ['sunny','hot','high','FALSE','no'],\n",
        "                ['sunny','hot','high','TRUE','no'],\n",
        "                ['overcast','hot','high','FALSE','yes'],\n",
        "              \n",
        "                ['rainy','mild','high','FALSE','yes'],\n",
        "                ['rainy','cool','normal','FALSE','yes'],\n",
        "                ['rainy','cool','normal','TRUE','no'],\n",
        "                ['overcast','cool','normal','TRUE','yes'],\n",
        "                ['sunny','mild','high','FALSE','no'],\n",
        "                ['sunny','cool','normal','FALSE','yes'],\n",
        "                ['rainy','mild','normal','FALSE','yes'],\n",
        "                ['sunny','mild','normal','TRUE','yes'],\n",
        "                ['overcast','mild','high','TRUE','yes'],\n",
        "                ['overcast','hot','normal','FALSE','yes'],\n",
        "                ['rainy','mild','high','TRUE','no']\n",
        "]\n",
        "header = ['outlook','temperature','humidity','windy','play']\n",
        "data = pd.DataFrame(training_data,columns=header)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpt7qhDcrdq-",
        "outputId": "34be8f62-1fcd-40a6-c3df-04e86be93c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>outlook</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windy</th>\n",
              "      <th>play</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sunny</td>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sunny</td>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>overcast</td>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rainy</td>\n",
              "      <td>mild</td>\n",
              "      <td>high</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rainy</td>\n",
              "      <td>cool</td>\n",
              "      <td>normal</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rainy</td>\n",
              "      <td>cool</td>\n",
              "      <td>normal</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>overcast</td>\n",
              "      <td>cool</td>\n",
              "      <td>normal</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sunny</td>\n",
              "      <td>mild</td>\n",
              "      <td>high</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sunny</td>\n",
              "      <td>cool</td>\n",
              "      <td>normal</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>rainy</td>\n",
              "      <td>mild</td>\n",
              "      <td>normal</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>sunny</td>\n",
              "      <td>mild</td>\n",
              "      <td>normal</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>overcast</td>\n",
              "      <td>mild</td>\n",
              "      <td>high</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>overcast</td>\n",
              "      <td>hot</td>\n",
              "      <td>normal</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>rainy</td>\n",
              "      <td>mild</td>\n",
              "      <td>high</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     outlook temperature humidity  windy play\n",
              "0      sunny         hot     high  FALSE   no\n",
              "1      sunny         hot     high   TRUE   no\n",
              "2   overcast         hot     high  FALSE  yes\n",
              "3      rainy        mild     high  FALSE  yes\n",
              "4      rainy        cool   normal  FALSE  yes\n",
              "5      rainy        cool   normal   TRUE   no\n",
              "6   overcast        cool   normal   TRUE  yes\n",
              "7      sunny        mild     high  FALSE   no\n",
              "8      sunny        cool   normal  FALSE  yes\n",
              "9      rainy        mild   normal  FALSE  yes\n",
              "10     sunny        mild   normal   TRUE  yes\n",
              "11  overcast        mild     high   TRUE  yes\n",
              "12  overcast         hot   normal  FALSE  yes\n",
              "13     rainy        mild     high   TRUE   no"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3At3s4Yrfch",
        "outputId": "72f2ea56-a261-43df-fcda-53f283b49767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "\n",
        "Classes ={}\n",
        "target = data.columns[-1]\n",
        "labels = data[target].unique()\n",
        "for i in data.columns[:-1]:\n",
        "  Columns = {}\n",
        "  for j in data[i].unique():\n",
        "    Probabilty = {}\n",
        "    for label in labels:\n",
        "      Probabilty[label] = round(data[i][data[i]==j].where(data[target] == label).count()/data[target].where(data[target] == label).count(),2)\n",
        "    Columns[j] = Probabilty\n",
        "  Classes[i] = Columns\n",
        "Classes\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'humidity': {'high': {'no': 0.8, 'yes': 0.33},\n",
              "  'normal': {'no': 0.2, 'yes': 0.67}},\n",
              " 'outlook': {'overcast': {'no': 0.0, 'yes': 0.44},\n",
              "  'rainy': {'no': 0.4, 'yes': 0.33},\n",
              "  'sunny': {'no': 0.6, 'yes': 0.22}},\n",
              " 'temperature': {'cool': {'no': 0.2, 'yes': 0.33},\n",
              "  'hot': {'no': 0.4, 'yes': 0.22},\n",
              "  'mild': {'no': 0.4, 'yes': 0.44}},\n",
              " 'windy': {'FALSE': {'no': 0.4, 'yes': 0.67},\n",
              "  'TRUE': {'no': 0.6, 'yes': 0.33}}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odrDT0NexrJD",
        "outputId": "b86b2f98-2356-46be-8182-4631eac9e67f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "for i in Classes.keys():\n",
        "  print(\"=========================\"+i+\"==============================\")\n",
        "  print(pd.DataFrame.from_dict({j: Classes[i][j]\n",
        "                           for j in Classes[i].keys()},\n",
        "                       orient='index'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================outlook==============================\n",
            "           no   yes\n",
            "sunny     0.6  0.22\n",
            "overcast  0.0  0.44\n",
            "rainy     0.4  0.33\n",
            "=========================temperature==============================\n",
            "       no   yes\n",
            "hot   0.4  0.22\n",
            "mild  0.4  0.44\n",
            "cool  0.2  0.33\n",
            "=========================humidity==============================\n",
            "         no   yes\n",
            "high    0.8  0.33\n",
            "normal  0.2  0.67\n",
            "=========================windy==============================\n",
            "        no   yes\n",
            "FALSE  0.4  0.67\n",
            "TRUE   0.6  0.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2fPVgVY3Yyz"
      },
      "source": [
        "Target = {}\n",
        "for label in labels:\n",
        "  Target[label] = data[target][data[target] == label].count()/data[target].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd9pZK12Bdeh",
        "outputId": "8d4d58e6-836b-4691-f83b-04237a7c94dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Target\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'no': 0.35714285714285715, 'yes': 0.6428571428571429}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbvFnqTABw8u",
        "outputId": "977cde96-afe7-423d-9614-e02390923291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "today = ('sunny', 'hot','normal','FALSE')\n",
        "Prob = {}\n",
        "for label in labels:\n",
        "  result=1\n",
        "  for i,j in zip(today,data.columns[:-1]):\n",
        "    result *= Classes[j][i][label]\n",
        "  Prob[label] = round(result*Target[label],4)\n",
        "print(Prob)\n",
        "max(Prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'no': 0.0069, 'yes': 0.014}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimruoP8FMw1",
        "outputId": "ca7a2528-6160-409d-c47d-131f97eaf007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "import pandas as pd\n",
        "training_data =[\n",
        "                ['sunny','hot','high','false','no'],\n",
        "                ['sunny','hot','high','true','no'],\n",
        "                ['overcast','hot','high','false','yes'],\n",
        "                ['rainy','mild','high','false','yes'],\n",
        "                ['rainy','cool','normal','false','yes'],\n",
        "                ['rainy','cool','normal','true','no'],\n",
        "                ['overcast','cool','normal','true','yes'],\n",
        "                ['sunny','mild','high','false','no'],\n",
        "                ['sunny','cool','normal','false','yes'],\n",
        "                ['rainy','mild','normal','false','yes'],\n",
        "                ['sunny','mild','normal','true','yes'],\n",
        "                ['overcast','mild','high','true','yes'],\n",
        "                ['overcast','hot','normal','false','yes'],\n",
        "                ['rainy','mild','high','true','no']]\n",
        "header = ['outlook','temperature','humidity','windy','play']\n",
        "\n",
        "class NaiveBayes:\n",
        "  def __init__(self,Data):\n",
        "    self.data = Data\n",
        "    self.target = self.data.columns[-1]\n",
        "    # self.columns = self.data.columns[:-1]\n",
        "    self.labels = self.data[self.target].unique()\n",
        "    self.Classes = dict()\n",
        "    self.Target = dict()\n",
        "\n",
        "  def PostereirProbability(self):\n",
        "\n",
        "    \"\"\" \n",
        "        This Function Generates the Probability Table of Each Column with refrence to Target value P(B|A)\n",
        "        P(Bi|Ai) = count(Bi){where Ai is known}/count(Ai)\n",
        "    \"\"\"\n",
        "\n",
        "    for column in self.data.columns[:-1]:\n",
        "      cols=dict()\n",
        "      for col_unique in self.data[column].unique():\n",
        "        probabilty_value = dict()\n",
        "        for label in self.labels:\n",
        "          count = self.data[column][self.data[column]==col_unique].where(self.data[self.target] == label).count()\n",
        "          probabilty_value[label] = round(count/self.data[self.target].where(self.data[self.target] == label).count(),4)\n",
        "        cols[col_unique] = probabilty_value\n",
        "      self.Classes[column] = cols\n",
        "\n",
        "  def displayProbability(self):\n",
        "    \"\"\" \n",
        "        This Function Display the Probability Table of Each Column with refrence to Target value\n",
        "        P(B|A)\n",
        "    \"\"\"\n",
        "    self.PostereirProbability()\n",
        "    print(\"Probability values for all the classes with respect to Target Labels:\")\n",
        "    for i in self.Classes.keys():\n",
        "      print(\"=========================\"+i.upper()+\"=========================\")\n",
        "      print(pd.DataFrame.from_dict({j: self.Classes[i][j] for j in self.Classes[i].keys()},orient='index'))\n",
        "\n",
        "  def getTarget(self):\n",
        "    \"\"\" \n",
        "        This Function Generates the Probability values of Individual Target Variable\n",
        "        ex : P(A1) = count(A1)/SUM(count(A1),count(A2),...,count(An))\n",
        "    \"\"\"\n",
        "    self.displayProbability()\n",
        "    for label in self.labels:\n",
        "      self.Target[label] = round(self.data[self.target][self.data[self.target] == label].count()/self.data[self.target].count(),4)\n",
        "    print(\"=========================Probability Of the Target Values=========================\\nP(A):\",self.Target)\n",
        "\n",
        "\n",
        "  def prediction(self,Value):\n",
        "    \"\"\"\n",
        "        This Function Predict the Taget class for Given Value by calculating P(A|B)\n",
        "        P(A|B) = P(B|A)*P(A)\n",
        "        INPUT: dict()\n",
        "        Output = Maximum(P(A1|B),P(A2|B),...,P(An|B))\n",
        "    \"\"\"\n",
        "\n",
        "    self.getTarget()\n",
        "    probability_target = dict()\n",
        "    for label in self.labels:\n",
        "      result = 1\n",
        "      for i,j in Value.items():\n",
        "        result *= self.Classes[i][j][label]\n",
        "      probability_target[label] = result*self.Target[label]\n",
        "    #To convert this into a probability by making the sum equal to 1 (normalization)\n",
        "\n",
        "    summation = sum(probability_target.values())\n",
        "    res = {key:round(value/summation,2) for key,value in probability_target.items()}\n",
        "    maximum = max(res, key=res.get) #key of maximum value\n",
        "    return (maximum,max(res.values()))\n",
        "\n",
        "def main():\n",
        "    print(\"=========================Naive Bayes Classifier=========================\")\n",
        "    df = pd.DataFrame(training_data,columns=header)\n",
        "    Values={}\n",
        "    print(\"Enter the Parameter to predict the Class Label\")\n",
        "    for i in df.columns[:-1]:\n",
        "      print(\"{} : from {}: \".format(i,df[i].unique()))\n",
        "      Values[i] =input()\n",
        " \n",
        "    naive_Bayes = NaiveBayes(df)\n",
        "    output,Probability = naive_Bayes.prediction(Values)\n",
        "    print(\"========================Output from Calssifier========================\")\n",
        "    print(\"\\nPridicted Class Label for given input parameter '{}' and  P(A|B): {} \".format(output,Probability))\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================Naive Bayes Classifier=========================\n",
            "Enter the Parameter to predict the Class Label\n",
            "outlook : from ['sunny' 'overcast' 'rainy']: \n",
            "rainy\n",
            "temperature : from ['hot' 'mild' 'cool']: \n",
            "cool\n",
            "humidity : from ['high' 'normal']: \n",
            "high\n",
            "windy : from ['false' 'true']: \n",
            "true\n",
            "Probability values for all the classes with respect to Target Labels:\n",
            "=========================OUTLOOK=========================\n",
            "           no     yes\n",
            "sunny     0.6  0.2222\n",
            "overcast  0.0  0.4444\n",
            "rainy     0.4  0.3333\n",
            "=========================TEMPERATURE=========================\n",
            "       no     yes\n",
            "hot   0.4  0.2222\n",
            "mild  0.4  0.4444\n",
            "cool  0.2  0.3333\n",
            "=========================HUMIDITY=========================\n",
            "         no     yes\n",
            "high    0.8  0.3333\n",
            "normal  0.2  0.6667\n",
            "=========================WINDY=========================\n",
            "        no     yes\n",
            "false  0.4  0.6667\n",
            "true   0.6  0.3333\n",
            "=========================Probability Of the Target Values=========================\n",
            "P(A): {'no': 0.3571, 'yes': 0.6429}\n",
            "========================Output from Calssifier========================\n",
            "\n",
            "Pridicted Class Label for given input parameter 'no' and  P(A|B): 0.63 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqPYS_LxDAIw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouUVvu5sUbof",
        "outputId": "b218aba6-11c7-4c2e-c167-dd741508742b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        " # #      Implement data smoothing techniques CO2\n",
        " \n",
        "# Smoothing by bin means : In smoothing by bin means, each value in a bin is replaced by the mean value of the bin.\n",
        "# Smoothing by bin median : In this method each bin value is replaced by its bin median value.\n",
        "# Smoothing by bin boundary : In smoothing by bin boundaries, the minimum and maximum values in a given bin are identified as the bin boundaries. Each bin value is then replaced by the closest boundary value.\n",
        " \n",
        "# Sort the array of given data set.\n",
        "# Divides the range into N intervals, each containing the approximately same number of samples(Equal-depth partitioning).\n",
        "# Store mean/ median/ boundaries in each row.\n",
        "import statistics\n",
        "class Smoothing:\n",
        "  def __init__(self,Array,bin):\n",
        "    self.data = Array\n",
        "    self.bin_size = bin\n",
        "    self.Bins = []\n",
        "  def initial_steps(self):\n",
        "    self.data = sorted(self.data)\n",
        "    for i in range(0,len(self.data),self.bin_size):\n",
        "      self.Bins.append(self.data[i:i+self.bin_size])\n",
        "    print(self.Bins)\n",
        " \n",
        "  def bin_mean(self):\n",
        "    print(\"Smoothing By Bin Mean\")\n",
        "    for i in range(len(self.Bins)):\n",
        "      mean = sum(self.Bins[i])//self.bin_size\n",
        "      self.Bins[i] = [mean for i in range(self.bin_size)]\n",
        "    print([i for j in self.Bins for i in j])\n",
        " \n",
        "  def bin_median(self):\n",
        "    print(\"Smoothing By Bin Median\")\n",
        "    for i in range(len(self.Bins)):\n",
        "      median = statistics.median(self.Bins[i])\n",
        "      self.Bins[i] = [median for i in range(self.bin_size)]\n",
        "    print([i for j in self.Bins for i in j])\n",
        " \n",
        "  def bin_boundary(self):\n",
        "    print(\"Smoothing By Bin Boundary \")\n",
        "    Binz = []\n",
        "    for i in self.Bins:\n",
        "      res = [i[0]] #for Lower Boundary value in bin\n",
        "      for j in range(1,len(i)-1):\n",
        "        if i[j]-i[0] <= i[-1]-i[j]:\n",
        "          res.append(i[0])\n",
        "        else:\n",
        "            res.append(i[-1])\n",
        "      res.append(i[-1])\n",
        "      Binz.append(res)\n",
        "    print([i for j in Binz for i in j])\n",
        " \n",
        "def main():\n",
        "    print(\"-----------Smoothing Techniques---------\")\n",
        "    print(\"Enter Array to be smoothed \")\n",
        "    Array = list(map(int,input().split(\",\")))\n",
        "    bin = int(input(\"Enter Bin size: \"))\n",
        "    S = Smoothing(Array,bin)\n",
        "    S.initial_steps()\n",
        "    print(\"Select a Smoothing method \\n1.Bin_mean\\n2.Bin_Median\\n3.Bin_Boundary\")\n",
        "    choice = int(input())\n",
        "    if choice == 1:\n",
        "      S.bin_mean()\n",
        "    elif choice == 2:\n",
        "      S.bin_median()\n",
        "    elif choice == 3:\n",
        "      S.bin_boundary()\n",
        "    else:\n",
        "      print(\"Incorrect Choice\")\n",
        " \n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------Smoothing Techniques---------\n",
            "Enter Array to be smoothed \n",
            "4,8,9,15,21,21,24,25,26,28,29,34\n",
            "Enter Bin size: 3\n",
            "[[4, 8, 9], [15, 21, 21], [24, 25, 26], [28, 29, 34]]\n",
            "Select a Smoothing method \n",
            "1.Bin_mean\n",
            "2.Bin_Median\n",
            "3.Bin_Boundary\n",
            "3\n",
            "Smoothing By Bin Boundary \n",
            "[4, 9, 9, 15, 21, 21, 24, 24, 26, 28, 28, 34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoDey69wReUt",
        "outputId": "571729d3-7655-4b2a-db4d-441abb06044a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        " \n",
        "import statistics as s\n",
        "class Normalization:\n",
        "    def __init__(self,Array):\n",
        "        self.data= Array\n",
        "    def minMax(self):\n",
        "        print(\"Original Min:{} Original Max:{}\".format(min(self.data),max(self.data)))\n",
        "        Min_max = [(i-min(self.data))/(max(self.data)-min(self.data)) for i in self.data]\n",
        "        return Min_max\n",
        "    def zScore(self):\n",
        "        ZScore= [round((i- s.mean(self.data))/s.pstdev(self.data),3) for i in self.data]\n",
        "        return ZScore\n",
        " \n",
        " \n",
        "def main():\n",
        "    print(\"Enter Data to be Normalized\")\n",
        "    data= list(map(int,input().split()))\n",
        "    print(\"Data:\",data)\n",
        "    norm= Normalization(data)\n",
        "    print(\"----------------Min-Max Normalization------------\")\n",
        "    print(norm.minMax())\n",
        "    print(\"------------------ZScore Normalization-------------\")\n",
        "    print(norm.zScore())\n",
        " \n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter Data to be Normalized\n",
            "200 300 400 600 1000\n",
            "Data: [200, 300, 400, 600, 1000]\n",
            "----------------Min-Max Normalization------------\n",
            "Original Min:200 Original Max:1000\n",
            "[0.0, 0.125, 0.25, 0.5, 1.0]\n",
            "------------------ZScore Normalization-------------\n",
            "[-1.061, -0.707, -0.354, 0.354, 1.768]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZnP-0oUEqOY"
      },
      "source": [
        "# To study about Data mining and Data Warehousing         CO2\n",
        "#    Create a pivot table and pivot chart on sample database in excel CO2\n",
        "#    Implement data smoothing techniques CO2\n",
        "#    Implement normalization techniques CO2\n",
        "#    To study about data mining tool: Weka CO1\n",
        "#    Implement APRIORI algorithm in Weka CO1\n",
        "#    Implement APRIORI Algorithm in JAVA CO1\n",
        "#    Implement Decision Tree classification in Weka CO1 \n",
        "#    Implement Decision Tree Classification in .Net/Python/Java CO1\n",
        "#    Implement Naïve  bayes algorithm in Weka CO1\n",
        "#    Implement Naïve  bayes Classification in .Net/Python/Java CO1\n",
        "#    Implement k-mean clustering algorithm CO1\n",
        " \n",
        "#    3 binning technique\n",
        "#    4 min max and z2 method\n",
        " \n",
        "#    first page title page collegename,subjectname,rollno,\n",
        "#    2nd page certificate\n",
        "#    3rd page index srno title page remarks\n",
        "#    from 4th page all the practicals\n",
        "# word and pdf file both updation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H-f0DRifPL5",
        "outputId": "80a16cf8-ac9c-4e2f-c409-aae329d11947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        " \n",
        "samples = [[185,72],[170,56],[168,60],[179,68],[182,72],[188,77],[180,71],[180,70],[183,84],[180,88],[180,67],[177,76]]\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n",
        "X = np.array(samples)\n",
        " \n",
        "plt.scatter(X[:,0], X[:,1], s=150)\n",
        "plt.show()\n",
        " \n",
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        " \n",
        "    def fit(self,data):\n",
        " \n",
        "        self.centroids = {}\n",
        " \n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        " \n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        " \n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        " \n",
        "            for featureset in data:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        " \n",
        "            prev_centroids = dict(self.centroids)\n",
        " \n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        " \n",
        "            optimized = True\n",
        " \n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100):\n",
        "                    optimized = False\n",
        " \n",
        "            if optimized:\n",
        "                break\n",
        " \n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "model = K_Means(k=2,max_iter=1)\n",
        "model.fit(X)\n",
        " \n",
        "for centroid in model.centroids:\n",
        "    plt.scatter(model.centroids[centroid][0], model.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "colors =['r','g','b']\n",
        "for classification in model.classifications:\n",
        "    color= colors[classification]\n",
        "    for featureset in model.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\n",
        "        \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}